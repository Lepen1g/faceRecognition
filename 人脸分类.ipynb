{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:393, test size:21\n",
      "WARNING:tensorflow:From <ipython-input-1-69fb9c2d2d65>:137: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "0 0.6757978\n",
      "0 0.52380955\n",
      "1 3.157924\n",
      "2 33.293335\n",
      "3 7.3282967\n",
      "4 3.6003575\n",
      "5 0.8135818\n",
      "6 1.3245252\n",
      "7 0.7717508\n",
      "8 0.6338441\n",
      "9 1.133323\n",
      "10 0.6649537\n",
      "11 1.1550064\n",
      "12 0.78698695\n",
      "13 0.8481058\n",
      "14 0.77082586\n",
      "15 0.7560619\n",
      "16 0.7733709\n",
      "17 0.69363993\n",
      "18 0.69846165\n",
      "***************acc = 0.52380955***************\n",
      "19 0.75227404\n",
      "20 0.72348577\n",
      "21 0.7584281\n",
      "22 0.76201427\n",
      "23 0.7542448\n",
      "24 0.75050175\n",
      "25 0.8873722\n",
      "26 0.565088\n",
      "27 0.71886444\n",
      "28 0.7167697\n",
      "29 0.72028327\n",
      "30 0.79863805\n",
      "31 0.6936474\n",
      "32 0.649982\n",
      "33 0.76760215\n",
      "34 0.7037692\n",
      "35 0.7451901\n",
      "36 0.8129385\n",
      "37 0.8554354\n",
      "***************acc = 0.52380955***************\n",
      "38 0.7052032\n",
      "39 0.7490498\n",
      "40 0.68204176\n",
      "41 0.6347543\n",
      "42 0.7450123\n",
      "43 0.81807995\n",
      "44 0.71251476\n",
      "45 0.7085127\n",
      "46 0.7294029\n",
      "47 0.74869597\n",
      "48 0.76677656\n",
      "49 0.66170067\n",
      "50 0.74845505\n",
      "51 0.64042294\n",
      "52 0.83503914\n",
      "53 0.7279565\n",
      "54 0.7419414\n",
      "55 0.748294\n",
      "56 0.74187016\n",
      "***************acc = 0.52380955***************\n",
      "57 0.68760526\n",
      "58 0.6896013\n",
      "59 0.6871421\n",
      "60 0.5879108\n",
      "61 0.70208335\n",
      "62 0.81654227\n",
      "63 0.77502275\n",
      "64 0.70241964\n",
      "65 0.69591045\n",
      "66 0.77968943\n",
      "67 0.7244719\n",
      "68 0.5967759\n",
      "69 0.7881867\n",
      "70 0.7731186\n",
      "71 0.8430468\n",
      "72 0.6933877\n",
      "73 0.69536066\n",
      "74 0.7745465\n",
      "75 0.77121764\n",
      "***************acc = 0.52380955***************\n",
      "76 0.7951578\n",
      "77 0.62790334\n",
      "78 0.6954514\n",
      "79 0.75758344\n",
      "80 0.7784657\n",
      "81 0.711075\n",
      "82 0.6978531\n",
      "83 0.81441116\n",
      "84 0.6547303\n",
      "85 0.7856646\n",
      "86 0.6965329\n",
      "87 0.7119628\n",
      "88 0.84805214\n",
      "89 0.64432144\n",
      "90 0.85497\n",
      "91 0.80045396\n",
      "92 0.6606692\n",
      "93 0.9036833\n",
      "94 0.6956696\n",
      "***************acc = 0.52380955***************\n",
      "95 0.6703919\n",
      "96 0.6506358\n",
      "97 0.682675\n",
      "98 0.6134616\n",
      "99 0.87553346\n",
      "100 0.73767626\n",
      "100 0.47619048\n",
      "101 0.7157655\n",
      "102 0.68104476\n",
      "103 0.62320566\n",
      "104 0.8059231\n",
      "105 0.7030797\n",
      "106 0.76447695\n",
      "107 0.7810737\n",
      "108 0.6649444\n",
      "109 0.8243874\n",
      "110 0.70231974\n",
      "111 0.7489604\n",
      "112 0.7551137\n",
      "113 0.66239345\n",
      "***************acc = 0.47619048***************\n",
      "114 0.6950965\n",
      "115 0.68676627\n",
      "116 0.6671872\n",
      "117 0.7688708\n",
      "118 0.718698\n",
      "119 0.6492531\n",
      "120 0.70523655\n",
      "121 0.7149147\n",
      "122 0.72129077\n",
      "123 0.7838351\n",
      "124 0.7483409\n",
      "125 0.7963113\n",
      "126 0.7223373\n",
      "127 0.63553345\n",
      "128 0.9564489\n",
      "129 0.80482274\n",
      "130 0.6623779\n",
      "131 0.7883817\n",
      "132 0.7460598\n",
      "***************acc = 0.47619048***************\n",
      "133 0.72392637\n",
      "134 0.83171844\n",
      "135 0.6968533\n",
      "136 0.72368246\n",
      "137 0.7634268\n",
      "138 0.7390481\n",
      "139 0.58266383\n",
      "140 0.71438485\n",
      "141 0.6783242\n",
      "142 0.79608727\n",
      "143 0.8201766\n",
      "144 0.67876756\n",
      "145 0.7222113\n",
      "146 0.6973529\n",
      "147 0.8342058\n",
      "148 0.7254329\n",
      "149 0.7021713\n",
      "150 0.815228\n",
      "151 0.66519415\n",
      "***************acc = 0.47619048***************\n",
      "152 0.66049707\n",
      "153 0.73740923\n",
      "154 0.65101844\n",
      "155 0.61184025\n",
      "156 0.684455\n",
      "157 0.7566263\n",
      "158 0.73544174\n",
      "159 0.6865902\n",
      "160 0.70161027\n",
      "161 0.7933645\n",
      "162 0.7669457\n",
      "163 0.7997722\n",
      "164 0.77942127\n",
      "165 0.6759302\n",
      "166 0.81110936\n",
      "167 0.7179357\n",
      "168 0.6727149\n",
      "169 0.81026447\n",
      "170 0.69587314\n",
      "***************acc = 0.47619048***************\n",
      "171 0.7226178\n",
      "172 0.79677117\n",
      "173 0.74479914\n",
      "174 0.71783996\n",
      "175 0.8254005\n",
      "176 0.6535664\n",
      "177 0.6792127\n",
      "178 0.75994843\n",
      "179 0.64278096\n",
      "180 0.8175801\n",
      "181 0.73130476\n",
      "182 0.7823135\n",
      "183 0.77700245\n",
      "184 0.74196166\n",
      "185 0.8465034\n",
      "186 0.6374432\n",
      "187 0.68167156\n",
      "188 0.8896739\n",
      "189 0.8011572\n",
      "***************acc = 0.47619048***************\n",
      "***************开始测试图片***************\n",
      "INFO:tensorflow:Restoring parameters from /home/leipeng/train_face_model/train_faces.cpkg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dlib' has no attribute 'get_frontal_face_detectr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69fb9c2d2d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;31m#使用dlib自带的frontal_face_detector作为我们的特征提取器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detectr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dlib' has no attribute 'get_frontal_face_detectr'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "\n",
    "my_faces_path = '/home/leipeng/facepicture/alyf'\n",
    "other_faces_path = '/home/leipeng/facepicture/aotherface_200'\n",
    "size = 64\n",
    "\n",
    "imgs = []\n",
    "labs = []\n",
    "\n",
    "def getPaddingSize(img):\n",
    "    h, w, _ = img.shape\n",
    "    top, bottom, left, right = (0,0,0,0)\n",
    "    longest = max(h, w)\n",
    "\n",
    "    if w < longest:\n",
    "        tmp = longest - w\n",
    "        # //表示整除符号\n",
    "        left = tmp // 2\n",
    "        right = tmp - left\n",
    "    elif h < longest:\n",
    "        tmp = longest - h\n",
    "        top = tmp // 2\n",
    "        bottom = tmp - top\n",
    "    else:\n",
    "        pass\n",
    "    return top, bottom, left, right\n",
    "\n",
    "def readData(path , h=size, w=size):\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            filename = path + '/' + filename\n",
    "\n",
    "            img = cv2.imread(filename)\n",
    "\n",
    "            top,bottom,left,right = getPaddingSize(img)\n",
    "            # 将图片放大， 扩充图片边缘部分\n",
    "            img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "            img = cv2.resize(img, (h, w))\n",
    "\n",
    "            imgs.append(img)\n",
    "            labs.append(path)\n",
    "\n",
    "readData(my_faces_path)\n",
    "readData(other_faces_path)\n",
    "# 将图片数据与标签转换成数组\n",
    "imgs = np.array(imgs)\n",
    "labs = np.array([[0,1] if lab == my_faces_path else [1,0] for lab in labs])\n",
    "# 随机划分测试集与训练集\n",
    "train_x,test_x,train_y,test_y = train_test_split(imgs, labs, test_size=0.05, random_state=random.randint(0,100))\n",
    "# 参数：图片数据的总数，图片的高、宽、通道\n",
    "train_x = train_x.reshape(train_x.shape[0], size, size, 3)\n",
    "test_x = test_x.reshape(test_x.shape[0], size, size, 3)\n",
    "# 将数据转换成小于1的数\n",
    "train_x = train_x.astype('float32')/255.0\n",
    "test_x = test_x.astype('float32')/255.0\n",
    "\n",
    "print('train size:%s, test size:%s' % (len(train_x), len(test_x)))\n",
    "# 图片块，每次取100张图片\n",
    "batch_size = 20\n",
    "num_batch = len(train_x) // batch_size\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, size, size, 3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "keep_prob_5 = tf.placeholder(tf.float32)\n",
    "keep_prob_75 = tf.placeholder(tf.float32)\n",
    "\n",
    "def weightVariable(shape):\n",
    "    init = tf.random_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def biasVariable(shape):\n",
    "    init = tf.random_normal(shape)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxPool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def dropout(x, keep):\n",
    "    return tf.nn.dropout(x, keep)\n",
    "\n",
    "def cnnLayer():\n",
    "    # 第一层\n",
    "    W1 = weightVariable([3,3,3,32]) # 卷积核大小(3,3)， 输入通道(3)， 输出通道(32)\n",
    "    b1 = biasVariable([32])\n",
    "    # 卷积\n",
    "    conv1 = tf.nn.relu(conv2d(x, W1) + b1)\n",
    "    # 池化\n",
    "    pool1 = maxPool(conv1)\n",
    "    # 减少过拟合，随机让某些权重不更新\n",
    "    drop1 = dropout(pool1, keep_prob_5)\n",
    "\n",
    "    # 第二层\n",
    "    W2 = weightVariable([3,3,32,64])\n",
    "    b2 = biasVariable([64])\n",
    "    conv2 = tf.nn.relu(conv2d(drop1, W2) + b2)\n",
    "    pool2 = maxPool(conv2)\n",
    "    drop2 = dropout(pool2, keep_prob_5)\n",
    "\n",
    "    # 第三层\n",
    "    W3 = weightVariable([3,3,64,64])\n",
    "    b3 = biasVariable([64])\n",
    "    conv3 = tf.nn.relu(conv2d(drop2, W3) + b3)\n",
    "    pool3 = maxPool(conv3)\n",
    "    drop3 = dropout(pool3, keep_prob_5)\n",
    "\n",
    "    # 全连接层\n",
    "    Wf = weightVariable([8*16*32, 512])\n",
    "    bf = biasVariable([512])\n",
    "    drop3_flat = tf.reshape(drop3, [-1, 8*16*32])\n",
    "    dense = tf.nn.relu(tf.matmul(drop3_flat, Wf) + bf)\n",
    "    dropf = dropout(dense, keep_prob_75)\n",
    "\n",
    "    # 输出层\n",
    "    Wout = weightVariable([512,2])\n",
    "    bout = weightVariable([2])\n",
    "    #out = tf.matmul(dropf, Wout) + bout\n",
    "    out = tf.add(tf.matmul(dropf, Wout), bout)\n",
    "    return out\n",
    "\n",
    "def cnnTrain():\n",
    "    break_flag = False\n",
    "    out = cnnLayer()\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y_))\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "    # 比较标签是否相等，再求的所有数的平均值，tf.cast(强制转换类型)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, 1), tf.argmax(y_, 1)), tf.float32))\n",
    "    # 将loss与accuracy保存以供tensorboard使用\n",
    "    tf.summary.scalar('loss', cross_entropy)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    # 数据保存器的初始化\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter('./tmp', graph=tf.get_default_graph())\n",
    "\n",
    "        for n in range(10):\n",
    "             # 每次取128(batch_size)张图片\n",
    "            for i in range(num_batch):\n",
    "                batch_x = train_x[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "                # 开始训练数据，同时训练三个变量，返回三个数据\n",
    "                _,loss,summary = sess.run([train_step, cross_entropy, merged_summary_op],\n",
    "                                           feed_dict={x:batch_x,y_:batch_y, keep_prob_5:0.5,keep_prob_75:0.75})\n",
    "                summary_writer.add_summary(summary, n*num_batch+i)\n",
    "                # 打印损失\n",
    "                print(n*num_batch+i, loss)\n",
    "\n",
    "                if (n*num_batch+i) % 100 == 0:\n",
    "                    # 获取测试数据的准确率\n",
    "                    acc = accuracy.eval({x:test_x, y_:test_y, keep_prob_5:1.0, keep_prob_75:1.0})\n",
    "                    print(n*num_batch+i, acc)\n",
    "                    # 准确率大于0.98时保存并退出\n",
    "                    if acc > 8 and n > 2:\n",
    "                        \n",
    "                        saver.save(sess,'/home/leipeng/train_face_model/train_faces.cpkg')\n",
    "                        print('——————————————————————存储模型完成——————————————————————')\n",
    "                        break_flag = True\n",
    "                        break\n",
    "                        #saver.save(sess,'/train_face_model/train_faces.model')\n",
    "                        #sys.exit(0)\n",
    "            if break_flag == True:\n",
    "                break\n",
    "                \n",
    "            print('***************acc = %s***************' % acc)\n",
    "cnnTrain()\n",
    "\n",
    "\n",
    "print('***************开始测试图片***************')\n",
    "\n",
    "\n",
    "#测试自己的数据\n",
    "%matplotlib inline\n",
    "input_dir_test = '/home/leipeng/facepicture/faceTest'\n",
    "index = 1\n",
    "\n",
    "output = cnnLayer()  \n",
    "predict = tf.argmax(output, 1)  \n",
    "\n",
    "saver = tf.train.import_meta_graph('/home/leipeng/train_face_model/train_faces.model.meta') \n",
    "sess = tf.Session()  \n",
    "saver.restore(sess, tf.train.latest_checkpoint('/home/leipeng/train_face_model/'))  \n",
    "\n",
    "def is_YifeiLiu_face(image):  \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    res = sess.run(predict, feed_dict={x: [image/255.0], keep_prob_5:1.0, keep_prob_75: 1.0})  \n",
    "    if res[0] == 1:  \n",
    "        return True  \n",
    "    else:  \n",
    "        return False  \n",
    "\n",
    "#使用dlib自带的frontal_face_detector作为我们的特征提取器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "for(path, dirnames, filenames) in os.walk(input_dir_test):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.jpg'):\n",
    "            print('开始处理第%s张预测图片：' % index)\n",
    "            index += 1\n",
    "            img_path = path + '/' + filename\n",
    "            #从文件读取图片\n",
    "            img = cv2.imread(img_path)\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            dets = detector(gray_image, 1)\n",
    "            if not len(dets):\n",
    "                print('不能获得图片')\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "\n",
    "            for i, d in enumerate(dets):\n",
    "                x1 = d.top() if d.top() > 0 else 0\n",
    "                y1 = d.bottom() if d.bottom() > 0 else 0\n",
    "                x2 = d.left() if d.left() > 0 else 0\n",
    "                y2 = d.right() if d.right() > 0 else 0\n",
    "                face = img[x1:y1,x2:y2]\n",
    "                # 调整图片的尺寸\n",
    "                face = cv2.resize(face, (size,size))\n",
    "                print('is this Yifei Liu:? %s' % is_YifeiLiu_face(face))\n",
    "\n",
    "                cv2.rectangle(img, (x2,x1),(y2,y1), (255,0,0),3)\n",
    "#                cv2.imshow('image',img)\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "\n",
    "sess.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
